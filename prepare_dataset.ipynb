{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "sys.path.append('/home/mbewley/Development/benthoz')\n",
    "logger = logging.getLogger()\n",
    "handler = logging.FileHandler('notebook_log.txt')\n",
    "handler.setLevel(logging.DEBUG)\n",
    "logger.handlers = [handler]\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import imageio\n",
    "import cv2\n",
    "\n",
    "import prep.image_fetcher\n",
    "import prep.label_converter\n",
    "\n",
    "\n",
    "os.chdir('/home/mbewley/Development/benthoz')\n",
    "IMAGE_PATH = 'images'\n",
    "if not os.path.exists(IMAGE_PATH):\n",
    "    os.mkdir(IMAGE_PATH)\n",
    "\n",
    "IMAGE_LIST_FILE = 'BENTHOZ-2015-imagelist.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation\n",
    "The first step is to:\n",
    "\n",
    "1. Acquire the images.\n",
    "2. Check they have been successfully acquired, by comparing them against the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep.image_fetcher.fetch_all_images(IMAGE_LIST_FILE, IMAGE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List number of downloaded images\n",
    "downloaded_images = [f.strip('.tif') for f in os.listdir(os.path.join(IMAGE_PATH)) if f.endswith('tif')]\n",
    "downloaded_images\n",
    "len(downloaded_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training = pd.read_csv('data_splits/public_labels_train.csv')\n",
    "df_training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_images = df_training.image_name.unique().tolist()\n",
    "\n",
    "missing_images = list(set(training_images) - set(downloaded_images) & set(training_images))\n",
    "missing_image_dates = set([s.split('_')[1] for s in missing_images])\n",
    "print(f'Missing {len(missing_images)} images on dates: {missing_image_dates}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the Hierarchy and Classes\n",
    "First, we need to look up the class IDs used in the data set, referencing them against class name as per `id_lookups.csv` (also part of the data set paper).\n",
    "We then need to build the heirarchy to define parent/child relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_id_lookups = prep.label_converter.build_hierarchy_from_id_lookup(id_lookup_file='idlookups.csv')\n",
    "df_id_lookups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_id_lookups = pd.read_csv('idlookups.csv', index_col=0)\n",
    "print(f'There are {len(df_id_lookups)} classes defined in the id lookup list')\n",
    "df_id_lookups.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The naming convention separates layers of the hierarchy with a colon ':', so we can break this into a list of descendents, and calculate the depth of the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_id_lookups['parsed_name'] = df_id_lookups.name.apply(lambda s: s.split(': '))\n",
    "df_id_lookups['depth'] = df_id_lookups.parsed_name.apply(lambda d: len(d))\n",
    "df_id_lookups.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two top nodes \"Biota\" and \"Physical\" are not prepended to their children, so we need to do this manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top level classes\n",
    "df_id_lookups.query('depth == 1').name.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually define biota and physical children\n",
    "\n",
    "biota_kids = ['Worms', 'Sponges', 'Seagrasses', 'Molluscs', 'Macroalgae', 'Jellies', 'Fishes', 'Echinoderms', 'Crustacea',\n",
    "              'Cnidaria', 'Bryozoa', 'Bioturbation', 'Bacterial mats', 'Ascidians']\n",
    "\n",
    "physical_kids = ['Substrate']\n",
    "\n",
    "# Prepend them to name lists, and add to depth.\n",
    "biota_inds = df_id_lookups.parsed_name.apply(lambda d: d[0] in biota_kids)\n",
    "df_id_lookups.loc[biota_inds, 'depth'] += 1\n",
    "df_id_lookups.loc[biota_inds, 'parsed_name'] = df_id_lookups.loc[biota_inds, 'parsed_name'].apply(lambda d: ['Biota'] + d)\n",
    "\n",
    "physical_inds = df_id_lookups.parsed_name.apply(lambda d: d[0] in physical_kids)\n",
    "df_id_lookups.loc[physical_inds, 'depth'] += 1\n",
    "df_id_lookups.loc[physical_inds, 'parsed_name'] = df_id_lookups.loc[physical_inds, 'parsed_name'].apply(lambda d: ['Physical'] + d)\n",
    "\n",
    "\n",
    "df_id_lookups['child_name'] = df_id_lookups.parsed_name.apply(lambda d: d[-1])\n",
    "\n",
    "display(df_id_lookups.head(10))\n",
    "display(df_id_lookups.sample(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert \"parsed_name\" to a list of node IDs, instead of strings\n",
    "\n",
    "def get_ancestor_ids(child_id):\n",
    "    parsed_name = df_id_lookups.loc[child_id, 'parsed_name']\n",
    "    ancestor_parsed_ids = []\n",
    "    for i in range(len(parsed_name)):\n",
    "        ancestor_parsed_name = parsed_name[:i+1]\n",
    "        ancestor_parsed_id = df_id_lookups[df_id_lookups.parsed_name.apply(lambda d: d == ancestor_parsed_name)].index[0]\n",
    "        ancestor_parsed_ids.append(ancestor_parsed_id)\n",
    "    return ancestor_parsed_ids\n",
    "\n",
    "\n",
    "df_id_lookups['ancestor_id_list'] = [get_ancestor_ids(d) for d in df_id_lookups.index]\n",
    "df_id_lookups = df_id_lookups.sort_index()\n",
    "df_id_lookups['bit_vector_idx'] = range(len(df_id_lookups))\n",
    "df_id_lookups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_id_lookups[df_id_lookups.name.str.startswith('Substrate')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now want to represent this class hierarchy as a bit-vector. Each class index has a unique bit in the vector (indexed by `id2ind`). A root level class will turn on a single bit. A depth 4 class will turn on 4 bits.\n",
    "\n",
    "This means that for an image, the label mask will be a 3D matrix of shape (`len(df_id_lookups)`, `im.shape[0]`, `im.shape[1]`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Sparse Points to Image Masks\n",
    "The next step is to convert the sparse lists of points in (image, row, column, label_id) form, to a 1:1 label mask per image. Initially, we will do this just as a classic multi class problem, with label_id = 0 as the placeholder for \"unknown\" pixels which should not be considered by the loss function. Later, we will use the hierarchical relationships between the labels to set it up as a multi-label problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "DONT_KNOW = -1\n",
    "NO = 0\n",
    "YES = 1\n",
    "\n",
    "def long_labels_to_multilabel_masks(rows, cols, label_ids, im_shape):\n",
    "    unique_label_ids = list(set(label_ids))\n",
    "    \n",
    "    # Stub out the label_mask to -1 for \"don't know\" unless otherwise specified.\n",
    "    label_masks = np.ones([len(df_id_lookups), im_shape[0], im_shape[1]], dtype=np.int8) * DONT_KNOW\n",
    "    for row, col, label_id in zip(*(rows, cols, label_ids)):\n",
    "        \n",
    "        # Now we know this particular pixel's value - zero it out, then flip on the relevant bits for the given class.\n",
    "        # TODO: This isn't quite right. We need to state any children (recursively) of the node are \"unknown\", so that \"Biota\" doesn't explicitly rule out kelp.\n",
    "        label_masks[:, row, col] = NO\n",
    "        \n",
    "        active_ids = df_id_lookups.loc[label_id, 'ancestor_id_list']\n",
    "        for active_id in active_ids:\n",
    "            bitvector_index = df_id_lookups.loc[active_id]['bit_vector_idx']\n",
    "#                 print(f'Storing ID {active_id} at bit index {bitvector_index}')\n",
    "            label_masks[bitvector_index, row, col] = YES\n",
    "    return label_masks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Convert long-form sparse point labels to \"don't know\" images. Treat this as multi-class for now (single image, with an indep label assigned to each point)\n",
    "\n",
    "def visualise_label_layer(label_id, im, labels):\n",
    "    bitvector_ind = df_id_lookups.loc[label_id]['bit_vector_idx']\n",
    "    print(f'Label {label_id} - displaying layer from bitvector_index {bitvector_ind}')\n",
    "    labels_single_layer = labels[bitvector_ind]\n",
    "    \n",
    "    # Get positive ones and dilate to make visible.\n",
    "    labels_single_layer = labels[bitvector_ind,:,:]\n",
    "\n",
    "\n",
    "    label_name = df_id_lookups.loc[label_id]['name']\n",
    "    plt.figure(figsize=(20,20))\n",
    "    plt.imshow(im)\n",
    "    \n",
    "    labels_pos = ((labels_single_layer == 1)).astype(np.uint8)\n",
    "    labels_pos_dilated = cv2.dilate(labels_pos, np.ones((9,9),np.uint8))\n",
    "    plt.imshow(labels_pos_dilated, alpha=labels_pos_dilated, cmap='brg')\n",
    "    \n",
    "    labels_neg = ((labels_single_layer == 0)).astype(np.uint8)\n",
    "    labels_neg_dilated = cv2.dilate(labels_neg, np.ones((9,9),np.uint8))\n",
    "    plt.imshow(labels_neg_dilated, alpha=labels_neg_dilated, cmap='seismic')\n",
    "\n",
    "    plt.title(label_name)\n",
    "    \n",
    "\n",
    "for i, (image_name, g) in enumerate(df_training.groupby('image_name')):\n",
    "    \n",
    "    # Get original image\n",
    "    im = cv2.imread(os.path.join(IMAGE_PATH, image_name+'.tif'))\n",
    "    labels = long_labels_to_multilabel_masks(g.row, g.col, g.label, im.shape[:2])\n",
    "    visualise_label_layer(400, im, labels)\n",
    "\n",
    "    if i > 3:\n",
    "        break\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}